{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "007f52df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8000,
     "status": "ok",
     "timestamp": 1649087474234,
     "user": {
      "displayName": "Daniel Rabayda",
      "userId": "03984531504935332105"
     },
     "user_tz": 240
    },
    "id": "007f52df",
    "outputId": "997385d6-e782-4dc9-a400-73ade9775b7a"
   },
   "outputs": [],
   "source": [
    "# Import Basic Python Functionality\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "74489cc3-5bb5-4f79-9b3b-0eddaadb1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Functions\n",
    "def time_str_to_secs(time_str): #changes time from \"MM:SS\" to it's value in seconds (starting at 00:00)\n",
    "    tmp_t=np.array(time_str.split(':')).astype('int')\n",
    "    return tmp_t[0]*60+tmp_t[1]\n",
    "\n",
    "def isnumber(st):\n",
    "    try:\n",
    "        int(st.split('-')[0])\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def isword(st): #returns true if a string is all alphabetic characters\n",
    "    alphabet=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','z','y']\n",
    "    c,ll=0,len(st)\n",
    "    for alph in st.lower():\n",
    "        if alph in alphabet:\n",
    "            c+=1\n",
    "    return c==ll\n",
    "\n",
    "def strs_to_labels(str_arr,ci=0,first_word=False): #takes in list of strings and outputs the first sequence of each that is not a word\n",
    "    labels=[]\n",
    "    for st in str_arr: #now loop through the \"label\" strings and pull out the first thing in that string that is not a word\n",
    "        st_sp=st.split(' ') #break up the string by spaces\n",
    "        c,alph=ci,'a' #ci is initial c, if we want to start at a different word in a string set ci higher, alph is just some alphanumeric word and isword will check if it is a word\n",
    "        while isword(alph): #loop through all the segments of a string delimited by spaces and pull out the first thing that's not 100% alphabetic\n",
    "            if c>=len(st_sp):\n",
    "                alph='_'\n",
    "            else:\n",
    "                alph=st_sp[c]\n",
    "            c+=1\n",
    "        if isnumber(alph[0]): #If our str looks like this Boeing 777 we want it to become B777 not just 777 so we add this part in\n",
    "            ind=c-2\n",
    "            if first_word: ind=0\n",
    "            alph=st_sp[ind][0]+alph\n",
    "        labels.append(alph)\n",
    "    return labels\n",
    "\n",
    "def relabeler(labels,pre_st='',to_remove=['F','N','neo','LR']): #to get rid of things like A330neo since it is mostly the same as the A330\n",
    "    labels_out=[]\n",
    "    for lb in labels:\n",
    "        tmp=lb\n",
    "        if pre_st in lb[:1]:\n",
    "            for si in to_remove:\n",
    "                if si in lb:\n",
    "                    tmp=lb.split(si)[0]\n",
    "        labels_out.append(tmp)\n",
    "    return labels_out\n",
    "\n",
    "def label_replacer(labels,replace_dict={'A530':'A330','A580':'A380','A550':'A350','AZ30':'A330','AZ21':'A321'}): #because sometimes the screen recorder messes up on predictable characters\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in list(replace_dict):\n",
    "            labels[i]=replace_dict[labels[i]]\n",
    "    return labels\n",
    "\n",
    "def full_relabel(labels): #relabel several times based on first character, i.e. relabel just boeing so that we remove the F from B737F but not have it affect Airbus A320F for example\n",
    "    return label_replacer(relabeler(relabeler(labels,pre_st='A',to_remove=['F','neo','-']),pre_st='E',to_remove=['-','LR']))\n",
    "\n",
    "def weight_extractor(labels,dicti):\n",
    "    weights,weight_classes=[],[]\n",
    "    for l in labels:\n",
    "        tmp_i=np.where(np.array(weight_labels)==dicti[l])[0][0]\n",
    "        weights.append(weight_raw_labels[:,1][tmp_i])\n",
    "        weight_classes.append(weight_raw_labels[:,-1][tmp_i])\n",
    "    return weights,weight_classes\n",
    "\n",
    "def generate_rough_dict(unique_a_labels,unique_w_labels,delim=',\\n'):\n",
    "    for a in unique_a_labels:\n",
    "        mt=difflib.get_close_matches(a,unique_w_labels,n=3)\n",
    "        if len(mt)==0: \n",
    "            print('\"'+a+'\":\"'+''+'\"',end=delim) \n",
    "        elif a==mt[0]:\n",
    "            print('\"'+a+'\":\"'+mt[0]+'\"',end=delim) \n",
    "        else:\n",
    "            mt=difflib.get_close_matches(a.split('-')[0],unique_w_labels,n=3)\n",
    "            if len(mt)==0: \n",
    "                print('\"'+a+'\":\"'+''+'\"',end=delim) \n",
    "            else:\n",
    "                print('\"'+a+'\":\"'+mt[0]+'\"',end=delim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0778314e-c2bd-43fa-a288-e8e97c259eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the datafile lengths\n",
    "[l_houston,l_berlin,l_amsterdam] = [3675, 3231, 7199]\n",
    "\n",
    "#import label data\n",
    "houston_times_labels=pd.read_csv('HoustonLabels.csv')[['start','stop','plane']].to_numpy()\n",
    "berlin_times_labels=pd.read_csv('BerlinLabels.csv').to_numpy() #Times, Str, Aircraft\n",
    "amsterdam_times_labels=pd.read_csv('AmsterdamLabels.csv')[['Raw Times(s)','Aircraft']].to_numpy()\n",
    "\n",
    "#format times\n",
    "houston_times=[[time_str_to_secs(time) for time in times] for times in houston_times_labels[:,:2]]\n",
    "berlin_times=berlin_times_labels[:,0]\n",
    "berlin_times=[time_str_to_secs(tm) for tm in berlin_times]+[l_berlin] #reformat into samples (also have to add the final time\n",
    "berlin_times=[[berlin_times[i],berlin_times[i+1]] for i in range(len(berlin_times)-1)] #reformat so the time is a pair with the end of one tag at the start of the next tag\n",
    "amsterdam_times=amsterdam_times_labels[:,0]\n",
    "amsterdam_times=[[amsterdam_times[i],amsterdam_times[i+1]] for i in range(len(amsterdam_times)-1)]+[[amsterdam_times[-1],l_amsterdam]]\n",
    "\n",
    "#format actual labels\n",
    "houston_labels=houston_times_labels[:,2]\n",
    "berlin_labels=strs_to_labels(berlin_times_labels[:,1],ci=2)\n",
    "#berlin_labels=[label.split('-')[0] for label in berlin_labels]\n",
    "amsterdam_labels=strs_to_labels(amsterdam_times_labels[:,1])\n",
    "amsterdam_labels=[label.split('(')[0] for label in amsterdam_labels] #here I make the decision to throw away the additional identifiers, i.e. A330-200 -> A330\n",
    "houston_labels,berlin_labels,amsterdam_labels=full_relabel(houston_labels),full_relabel(berlin_labels),full_relabel(amsterdam_labels)\n",
    "\n",
    "#Import Weights Data\n",
    "weight_raw_labels=pd.read_csv('aircraft_weight_classes.csv')[['type-[]','MTOW [kg]','ICAO category','FAA category']].to_numpy()\n",
    "weight_labels=strs_to_labels(weight_raw_labels[:,0],first_word=True)\n",
    "weight_labels=full_relabel(weight_labels)\n",
    "\n",
    "h_to_w_dict={\"A220\":\"A220\",\"A300\":\"A300\",\"A319\":\"A319\",\"A320\":\"A320\",\"A320N\":\"A320\",\"A321\":\"A321\",\"A350\":\"A350\",\"A380\":\"A380\",\"B737\":\"B737-300\",\"B747F\":\"B747-8F\",\"B767\":\"B767-300\",\"B767F\":\"B767-300\",\"B777\":\"B777F\",\"B777F\":\"B777F\",\"CRJ1000\":\"CRJ-1000\",\"CRJ200\":\"CRJ-200\",\"CRJ900\":\"CRJ-900\",\"E145\":\"E145\",\"E175\":\"E175\",\"E190\":\"E190\",\"MD80\":\"McDonnell-Douglas\",\"tiny\":\"E100\"}\n",
    "b_to_w_dict={\"A318\":\"A318\",\"A319\":\"A319\",\"A320\":\"A320\",\"A321\":\"A321\",\"A330\":\"A330\",\"B737-800\":\"B737-800\",\"B737-900\":\"B737-900\",\"B767-300ER\":\"B767-300ER\",\"B787-8\":\"B787-8\",\"E190\":\"E190\",\"E195\":\"E195\"}\n",
    "a_to_w_dict={\"A300\":\"A300\",\"A310\":\"A310\",\"A318\":\"A318\",\"A319\":\"A319\",\"A320\":\"A320\",\"A321\":\"A321\",\"A330\":\"A330\",\"A350\":\"A350\",\"A380\":\"A380\",\"B737\":\"B737-300\",\"B737-700\":\"B737-700\",\"B737-800\":\"B737-800\",\"B747-400F\":\"B747-400\",\"B747-8F\":\"B747-8F\",\"B767-300ER\":\"B767-300ER\",\"B767-300F\":\"B767-300\",\"B777-200ER\":\"B777-200ER\",\"B777-300ER\":\"B777-300ER\",\"B777F\":\"B777F\",\"B787-10\":\"B787-10\",\"B787-8\":\"B787-8\",\"B787-9\":\"B787-9\",\"CRJ-1000\":\"CRJ-1000\",\"CRJ-1000EL\":\"CRJ-1000EL\",\"CRJ-900ER\":\"CRJ-900\",\"CRJ-900LR\":\"CRJ-900\",\"Dash-8-Q400\":\"Dash-8-Q400\",\"E175\":\"E175\",\"E190\":\"E190\",\"E195\":\"E195\"}\n",
    "\n",
    "houston_weights,houston_weight_classes=weight_extractor(houston_labels,h_to_w_dict)\n",
    "berlin_weights,berlin_weight_classes=weight_extractor(berlin_labels,b_to_w_dict)\n",
    "amsterdam_weights,amsterdam_weight_classes=weight_extractor(amsterdam_labels,a_to_w_dict)\n",
    "\n",
    "to_df = lambda labels,times,weights,w_classes:pd.DataFrame({\"labels\":labels,\"start\":np.array(times)[:,0],\"stop\":np.array(times)[:,1],\"weight\":weights,\"w_classes\":w_classes})\n",
    "\n",
    "houston_df=to_df(houston_labels,houston_times,houston_weights,houston_weight_classes)\n",
    "berlin_df=to_df(berlin_labels,berlin_times,berlin_weights,berlin_weight_classes)\n",
    "amsterdam_df=to_df(amsterdam_labels,amsterdam_times,amsterdam_weights,amsterdam_weight_classes)\n",
    "\n",
    "houston_df.to_csv('houston.csv',index=False)\n",
    "berlin_df.to_csv('berlin.csv',index=False)\n",
    "amsterdam_df.to_csv('amsterdam.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32dcb2-acf1-4116-b957-735406db44ea",
   "metadata": {},
   "source": [
    "# Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1a440842-0f59-4a53-be11-eb004c4a0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "Australia_info=pd.read_csv('Hours_of_Australia.csv')\n",
    "flat = lambda na:[v for a in na for v in a] #flattens a list of lists into just a list\n",
    "\n",
    "raw_sts=Australia_info[['video']].to_numpy().astype('str')\n",
    "sep_inds=[i for i in range(len(raw_sts)) if raw_sts[i][0]!='nan' and raw_sts[i][0][0]!='h']+[len(raw_sts)] #a!='nan'\n",
    "\n",
    "Australia_Times=[flat(Australia_info[['Labeled Time(s)']][sep_inds[i]:sep_inds[i+1]].to_numpy().astype('int')) for i in range(len(sep_inds)-1)]\n",
    "Australia_vid_lengths=flat(Australia_info[['video lengths(s)']][:36].to_numpy().astype('int')) #-1 just incase the videos are not actually as long as they say\n",
    "for i in range(len(Australia_Times)):\n",
    "    Australia_Times[i].append(Australia_vid_lengths[i]) #add the video length to the end of each times list\n",
    "Australia_Times=[[[tl[i],tl[i+1]] for i in range(len(tl)-1)] for tl in Australia_Times] #rewrite times as start and stop times instead\n",
    "\n",
    "Australia_Labels=[flat(Australia_info[['Labels']][sep_inds[i]:sep_inds[i+1]].to_numpy().astype('str')) for i in range(len(sep_inds)-1)]\n",
    "Australia_Labels=[strs_to_labels(lbls) for lbls in Australia_Labels]\n",
    "Australia_Labels=[full_relabel(lbls) for lbls in Australia_Labels]\n",
    "\n",
    "#dict made using unique_aus_labels=np.unique(flat(Australia_Labels)).tolist();unique_w_labels=np.unique(weight_labels).tolist();generate_rough_dict(unique_aus_labels,unique_w_labels)\n",
    "aus_to_w_dict={\"A319\":\"A319\",\"A320\":\"A320\",\"A321\":\"A321\",\"A330\":\"A330\",\"A340\":\"A340\",\"A350\":\"A350\",\"A380\":\"A380\",\"A72\":\"A72\",\"AN\":\"An\",\"B717-200\":\"B717-200BGW\",\"B737\":\"B737-300\",\"B737-300\":\"B737-300\",\"B737-300F\":\"B737-300\",\"B737-400F\":\"B737-400\",\"B737-700\":\"B737-700\",\"B737-700BBJ\":\"B737-700\",\"B737-800\":\"B737-800\",\"B737-900\":\"B737-900\",\"B737F\":\"B737-300\",\"B747\":\"B747-8\",\"B747-400\":\"B747-400\",\"B747-400ER\":\"B747-400ER\",\"B747-400F\":\"B747-400ER\",\"B747-8F\":\"B747-8F\",\"B747F\":\"B747-8F\",\"B757-200\":\"B757-200\",\"B757-200F\":\"B757-200\",\"B757F\":\"B757-200\",\"B767\":\"B767-300\",\"B767-300\":\"B767-300\",\"B767-300ER\":\"B767-300ER\",\"B767-300ERF\":\"B767-300ER\",\"B767-300F\":\"B767-300ER\",\"B767-30F\":\"B767-300ER\",\"B767F\":\"B777F\",\"B777\":\"B777F\",\"B777-200\":\"B777-200ER\",\"B777-200ER\":\"B777-200ER\",\"B777-200F\":\"B777-200ER\",\"B777-200LR\":\"B777-200LR\",\"B777-300\":\"B777-300\",\"B777-300ER\":\"B777-300ER\",\"B777F\":\"B777F\",\"B787\":\"B787-9\",\"B787-10\":\"B787-10\",\"B787-8\":\"B787-8\",\"B787-800\":\"B787-8\",\"B787-9\":\"B787-9\",\"B787=9\":\"B787-9\",\"BAe-146-200QTF\":\"BAE-146\",\"BAe-146-300QTF\":\"BAE-146\",\"C-130J\":\"C-130J\",\"C-17\":\"C-17\",\"D8\":\"Dash-8-Q400\",\"DC-3\":\"DC-7\",\"Dash-8\":\"Dash-8-Q400\",\"E170\":\"E170\",\"E190\":\"E190\",\"F100\":\"F100\",\"G6000\":\"G6000\",\"IL-76\":\"IL-76\",\"KC-30\":\"KC-30\",\"MD-11F\":\"McDonnell-Douglas\",\"RAAFFalcon7x\":\"RAAFFalcon7x\",\"RJ-100\":\"RJ-100\",\"S340\":\"S340\"}\n",
    "\n",
    "Australia_weights=[weight_extractor(lbls,aus_to_w_dict)[0] for lbls in Australia_Labels]\n",
    "Australia_weight_classes=[weight_extractor(lbls,aus_to_w_dict)[1] for lbls in Australia_Labels]\n",
    "\n",
    "Australia_dfs=[to_df(Australia_Labels[i],Australia_Times[i],Australia_weights[i],Australia_weight_classes[i]) for i in range(len(Australia_Labels))]\n",
    "for i in range(len(Australia_dfs)):\n",
    "    Australia_dfs[i].to_csv('Australia_'+str(i)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7e1229a1-073a-43b7-b6e6-e9ce2aac5daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2000, 2146],\n",
       " [1783, 1977],\n",
       " [1908, 1264],\n",
       " [1673, 1252],\n",
       " [1217, 1359],\n",
       " [1206, 1293],\n",
       " [1465, 1518],\n",
       " [1640, 1707],\n",
       " [1544, 1632],\n",
       " [1206, 1249],\n",
       " [1278, 1347],\n",
       " [1232, 1307],\n",
       " [1406, 1469],\n",
       " [1340, 1404],\n",
       " [1279, 1366],\n",
       " [1856, 1915],\n",
       " [1562, 1636],\n",
       " [1454, 1508],\n",
       " [1257, 1348],\n",
       " [1218, 1275],\n",
       " [1241, 1294],\n",
       " [1242, 1308],\n",
       " [1199, 1264],\n",
       " [8522, 8572],\n",
       " [1756, 1822],\n",
       " [1213, 1273],\n",
       " [1105, 1182],\n",
       " [1140, 1205],\n",
       " [1143, 1202],\n",
       " [1308, 1365],\n",
       " [1251, 1310],\n",
       " [1592, 1668],\n",
       " [1169, 1252],\n",
       " [1117, 1204],\n",
       " [1214, 1355],\n",
       " [1162, 1225]]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[time[-1] for time in Australia_Times]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377d981-6537-47ef-9f0b-a2ec5eca0ed2",
   "metadata": {},
   "source": [
    "# Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a02a52-dd63-452e-81d1-42ca0696eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to get the list of youtube video links\n",
    "#[a for l in Australia_info[['video']].to_numpy().astype('str') for a in l if a[0]=='h'] #a!='nan' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "995c1111-6ed5-41bf-8148-8d2042714750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the below code to generate a_to_w_dict (needs to be manually adjusted for best fit)\n",
    "# Use the below code to generate a_to_w_dict (needs to be manually adjusted for best fit)\n",
    "unique_aus_labels=np.unique(flat(Australia_Labels)).tolist();unique_w_labels=np.unique(weight_labels).tolist();generate_rough_dict(unique_aus_labels,unique_w_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb4e7f8-f866-4b70-b395-8555a3950f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1,  2, 25]), array([], dtype=int64), array([], dtype=int64)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcs=[houston_weight_classes,berlin_weight_classes,amsterdam_weight_classes]\n",
    "[np.where(np.array(wc)=='Small')[0] for wc in wcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0bcf44f8-6a5d-4193-a275-5bc83a68d8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 total classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A220',\n",
       " 'A300',\n",
       " 'A310',\n",
       " 'A318',\n",
       " 'A319',\n",
       " 'A320',\n",
       " 'A320N',\n",
       " 'A321',\n",
       " 'A330',\n",
       " 'A350',\n",
       " 'A380',\n",
       " 'B737',\n",
       " 'B737-700',\n",
       " 'B737-800',\n",
       " 'B737-900',\n",
       " 'B747-400F',\n",
       " 'B747-8F',\n",
       " 'B747F',\n",
       " 'B767',\n",
       " 'B767-300ER',\n",
       " 'B767-300F',\n",
       " 'B767F',\n",
       " 'B777',\n",
       " 'B777-200ER',\n",
       " 'B777-300ER',\n",
       " 'B777F',\n",
       " 'B787-10',\n",
       " 'B787-8',\n",
       " 'B787-9',\n",
       " 'CRJ-1000',\n",
       " 'CRJ-1000EL',\n",
       " 'CRJ-900ER',\n",
       " 'CRJ-900LR',\n",
       " 'CRJ1000',\n",
       " 'CRJ200',\n",
       " 'CRJ900',\n",
       " 'Dash-8-Q400',\n",
       " 'E145',\n",
       " 'E175',\n",
       " 'E190',\n",
       " 'E195',\n",
       " 'MD80',\n",
       " 'tiny']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbs=[houston_labels,berlin_labels,amsterdam_labels]\n",
    "all_classes=np.unique([a for lst in [np.unique(lb).tolist() for lb in lbs] for a in lst]).tolist()\n",
    "print(len(all_classes),\"total classes\")\n",
    "all_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb0c60-7bf6-4856-ad99-7bfeb551fa11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "b0bd3ee2",
    "d45a5f79",
    "07e85bfa",
    "1222f42a-0d69-4587-b3e9-eac7f408121f",
    "792e9feb-807e-4901-8725-7ad05287127f",
    "f8321602"
   ],
   "name": "NoiseNet_20220325_DPR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
